# -*- coding: utf-8 -*-
import requests
from bs4 import BeautifulSoup
import os
import json
import argparse
import re
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed # <--- ä¿®å¤: è¡¥ä¸Š as_completed çš„å¯¼å…¥

# --- ç¿»è¯‘æ¨¡å— ---
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    OpenAI = None

# ==============================================================================
# 0. å…¨å±€é…ç½®ä¸Žå·¥å…·å‡½æ•°
# ==============================================================================
def log_message(message):
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {message}")

session = requests.Session()
session.headers.update({
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
})

def get_soup(url, parser='html.parser'):
    try:
        response = session.get(url, timeout=45)
        response.raise_for_status()
        return BeautifulSoup(response.content, parser)
    except requests.RequestException as e:
        log_message(f"âŒ è¯·æ±‚å¤±è´¥: {url}: {e}")
        return None

# ==============================================================================
# 1. å„æœŸåˆŠæŠ“å–å‡½æ•° (ä¸å†ä½¿ç”¨ç±»ï¼Œç›´æŽ¥ç”¨å‡½æ•°ï¼Œæ›´ç®€æ´)
# ==============================================================================

# --- AER æŠ“å–å‡½æ•° ---
def fetch_aer():
    log_message("ðŸ” [AER] æ­£åœ¨æŠ“å–å®˜ç½‘...")
    url = 'https://www.aeaweb.org/journals/aer/current-issue'
    soup = get_soup(url)
    if not soup: return [], None

    header_tag = soup.find('h1', class_='issue')
    vol, iss = (match.groups() if (match := re.search(r'Vol\.\s*(\d+),\s*No\.\s*(\d+)', header_tag.text)) else (None, None)) if header_tag else (None, None)
    report_header = f"ç¬¬{vol}å·(Vol. {vol}), ç¬¬{iss}æœŸ" if vol and iss else None
    
    article_ids = [a.get('id') for a in soup.find_all('article', class_='journal-article') if a.get('id') and 'symposia-title' not in a.get('class', [])]
    log_message(f"âœ… [AER] æ‰¾åˆ° {len(article_ids)} ä¸ªæ–‡ç« IDã€‚")

    articles = []
    with ThreadPoolExecutor(max_workers=5) as executor:
        future_to_id = {executor.submit(fetch_aer_detail, aid): aid for aid in article_ids}
        for future in as_completed(future_to_id):
            if result := future.result():
                articles.append(result)
    return articles, report_header

def fetch_aer_detail(article_id):
    url = f'https://www.aeaweb.org/articles?id={article_id}'
    soup = get_soup(url)
    if not soup: return None
    try:
        title = soup.find(class_='title').get_text(strip=True)
        authors = ", ".join([a.get_text(strip=True) for a in soup.select('.attribution .author')])
        abstract_tag = soup.find('section', class_='article-information abstract')
        raw_text = abstract_tag.get_text(strip=True) if abstract_tag else ""
        abstract = ' '.join((raw_text[8:] if raw_text.lower().startswith('abstract') else raw_text).split())
        return {'url': url, 'title': title, 'authors': authors or 'ä½œè€…æœªæ‰¾åˆ°', 'abstract': abstract or 'æ‘˜è¦æœªæ‰¾åˆ°'}
    except Exception as e:
        log_message(f"  âŒ [AER] è§£æžè¯¦æƒ…é¡µå¤±è´¥ for ID {article_id}: {e}")
        return None

# --- RSS æŠ“å–é€šç”¨å‡½æ•° ---
def fetch_from_rss(journal_name, rss_url, item_parser, item_filter=lambda item: True):
    log_message(f"ðŸ” [{journal_name}] æ­£åœ¨ä»Ž RSS Feed èŽ·å–æ–‡ç« ...")
    soup = get_soup(rss_url, parser='lxml') # ä½¿ç”¨ lxml è§£æžå™¨
    if not soup: return [], None

    items = [item for item in soup.find_all('item') if item_filter(item)]
    articles = [item_parser(item) for item in items]
    
    first_item = items[0] if items else None
    vol = iss = None
    if first_item:
        if (vol_tag := first_item.find('prism:volume')): vol = vol_tag.text.strip()
        if (iss_tag := first_item.find('prism:number')): iss = iss_tag.text.strip()
    report_header = f"ç¬¬{vol}å·(Vol. {vol}), ç¬¬{iss}æœŸ" if vol and iss else None
    
    return articles, report_header

# --- å„RSSæœŸåˆŠçš„è§£æžå™¨å’Œè¿‡æ»¤å™¨ ---
def oup_parser(item):
    desc_html = BeautifulSoup(item.description.text, 'html.parser')
    abstract_div = desc_html.find('div', class_='boxTitle')
    abstract = abstract_div.next_sibling.strip() if abstract_div and abstract_div.next_sibling else "æ‘˜è¦ä¸å¯ç”¨"
    return {'url': item.link.text.strip(), 'title': item.title.text.strip(), 'authors': 'ä½œè€…ä¿¡æ¯æœªåœ¨RSSä¸­æä¾›', 'abstract': abstract}

def ecta_parser(item):
    abstract_html = item.find('content:encoded').text.strip()
    return {'url': item.link.text.strip(), 'title': item.title.text.strip(), 'authors': item.find('dc:creator').text.strip(), 'abstract': BeautifulSoup(abstract_html, 'html.parser').get_text().strip()}

def ecta_filter(item):
    return item.find('dc:creator') and item.find('dc:creator').text.strip()

def jpe_parser(item):
    return {'url': item.link.text.strip(), 'title': item.title.text.strip(), 'authors': item.find('dc:creator').text.strip(), 'abstract': 'æ‘˜è¦éœ€è®¿é—®åŽŸæ–‡é“¾æŽ¥æŸ¥çœ‹'}

def jpe_filter(item):
    return item.find('dc:creator') and "Ahead of Print" not in item.description.text

# ==============================================================================
# 2. æ ¸å¿ƒå¤„ç†é€»è¾‘
# ==============================================================================
def translate_with_kimi(text, kimi_client):
    if not text or "not found" in text.lower() or "not available" in text.lower() or "æœªæä¾›" in text or "éœ€è®¿é—®" in text: return text
    if not kimi_client: return "(æœªç¿»è¯‘)"
    try:
        response = kimi_client.chat.completions.create(
            model="moonshot-v1-8k",
            messages=[{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç»æµŽå­¦é¢†åŸŸç¿»è¯‘åŠ©æ‰‹ã€‚è¯·å°†ç”¨æˆ·æä¾›çš„è‹±æ–‡æ–‡æœ¬å‡†ç¡®ã€æµç•…åœ°ç¿»è¯‘æˆä¸­æ–‡ã€‚è¯·ç›´æŽ¥è¾“å‡ºç¿»è¯‘ç»“æžœï¼Œä¸è¦åŒ…å«ä»»ä½•é¢å¤–è¯´æ˜Žæˆ–å®¢å¥—è¯ã€‚"},
                      {"role": "user", "content": text}],
            temperature=0.3, max_tokens=2000
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        log_message(f"Kimiç¿»è¯‘å¤±è´¥: {str(e)[:100]}...")
        return f"ç¿»è¯‘å¤±è´¥: {e}"

def process_journal(journal_key, kimi_client):
    log_message(f"--- å¼€å§‹å¤„ç†: {journal_key} ---")
    
    full_journal_names = {"AER": "American Economic Review", "JPE": "Journal of Political Economy", "QJE": "The Quarterly Journal of Economics", "RES": "The Review of Economic Studies", "ECTA": "Econometrica"}
    
    fetch_map = {
        "AER": fetch_aer,
        "JPE": lambda: fetch_from_rss("JPE", "https://www.journals.uchicago.edu/action/showFeed?ui=0&mi=0&ai=t6&jc=jpe&type=etoc&feed=rss", jpe_parser, jpe_filter),
        "QJE": lambda: fetch_from_rss("QJE", "https://academic.oup.com/rss/site_5504/3365.xml", oup_parser),
        "RES": lambda: fetch_from_rss("RES", "https://academic.oup.com/rss/site_5508/3369.xml", oup_parser),
        "ECTA": lambda: fetch_from_rss("ECTA", "https://onlinelibrary.wiley.com/feed/14680262/most-recent", ecta_parser, ecta_filter),
    }

    output_data = {} # å…ˆåˆå§‹åŒ–
    try:
        raw_articles, report_header = fetch_map[journal_key]()
        log_message(f"âœ… æ‰¾åˆ° {len(raw_articles)} ç¯‡æ¥è‡ª {journal_key} çš„æœ‰æ•ˆæ–‡ç« ã€‚")
        
        # --- !! å…³é”®ä¿®å¤ï¼šé‡‡ç”¨æ›´æ¸…æ™°ã€æ›´å®‰å…¨çš„æ–¹å¼å¤„ç† Future å¯¹è±¡ !! ---
        
        # 1. æäº¤æ‰€æœ‰ç¿»è¯‘ä»»åŠ¡
        if raw_articles:
            with ThreadPoolExecutor(max_workers=8) as executor:
                for article in raw_articles:
                    article['title_cn_future'] = executor.submit(translate_with_kimi, article['title'], kimi_client)
                    article['abstract_cn_future'] = executor.submit(translate_with_kimi, article['abstract'], kimi_client)

        # 2. åˆ›å»ºä¸€ä¸ªæ–°çš„åˆ—è¡¨æ¥å­˜å‚¨æœ€ç»ˆç»“æžœï¼Œå¹¶é€ä¸ªèŽ·å– Future çš„ç»“æžœ
        processed_articles = []
        for article in raw_articles:
            # èŽ·å–ç¿»è¯‘ç»“æžœ
            title_cn = article.pop('title_cn_future').result()
            abstract_cn = article.pop('abstract_cn_future').result()
            
            # å°† article å­—å…¸çš„å‰©ä½™éƒ¨åˆ†ä¸Žæ–°èŽ·å–çš„ç»“æžœåˆå¹¶
            # æ³¨æ„ï¼šæˆ‘ä»¬åœ¨è¿™é‡Œåˆ›å»ºäº†ä¸€ä¸ªæ–°çš„å­—å…¸ï¼Œè€Œä¸æ˜¯ä¿®æ”¹åŽŸå§‹å­—å…¸
            final_article = {
                **article,
                'title_cn': title_cn,
                'abstract_cn': abstract_cn
            }
            processed_articles.append(final_article)
        # --- !! ä¿®å¤ç»“æŸ !! ---
        
        output_data = {
            "journal_key": journal_key, 
            "journal_full_name": full_journal_names[journal_key], 
            "report_header": report_header or "æœ€æ–°ä¸€æœŸ", 
            "update_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC'), 
            "articles": processed_articles
        }
        
    except Exception as e:
        log_message(f"âŒ å¤„ç† {journal_key} æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        output_data = {
            "journal_key": journal_key, 
            "journal_full_name": full_journal_names.get(journal_key, "Unknown"), 
            "error": str(e), 
            "articles": []
        }
    
    with open(f"{journal_key}.json", 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=4)
    log_message(f"âœ… å·²å°† {journal_key} çš„æ•°æ®å†™å…¥åˆ° {journal_key}.json")

# ==============================================================================
# 3. ç¨‹åºå…¥å£
# ==============================================================================
def main():
    parser = argparse.ArgumentParser(description="é€šè¿‡æ··åˆç­–ç•¥æŠ“å–ç»æµŽå­¦æœŸåˆŠæœ€æ–°è®ºæ–‡ã€‚")
    parser.add_argument("journal", help="è¦æŠ“å–çš„æœŸåˆŠä»£ç  (e.g., AER, JPE)ã€‚")
    args = parser.parse_args()

    kimi_api_key = os.getenv('KIMI_API_KEY')
    kimi_client = None
    if OPENAI_AVAILABLE and kimi_api_key:
        try:
            kimi_client = OpenAI(api_key=kimi_api_key, base_url="https://api.moonshot.cn/v1")
            log_message("Kimi API å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸã€‚")
        except Exception as e:
            log_message(f"åˆå§‹åŒ–Kimiå®¢æˆ·ç«¯å¤±è´¥: {e}")
    else:
        log_message("KIMI_API_KEY çŽ¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œå°†ä¸è¿›è¡Œç¿»è¯‘ã€‚")

    if args.journal.upper() in ["AER", "JPE", "QJE", "RES", "ECTA"]:
        process_journal(args.journal.upper(), kimi_client)
    else:
        log_message(f"é”™è¯¯: ä¸æ”¯æŒçš„æœŸåˆŠä»£ç  '{args.journal}'.")

if __name__ == "__main__":
    main()
